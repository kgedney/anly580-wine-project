{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use kaggle data to train models\n",
    "# then will test on my scraped dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective: \n",
    "I plan to use the Word2Vec algorithm to train a new set of embeddings representative of the wine domain, then use those embeddings to fit a LTSM classification model. I also will plan on implementing a more simple, baseline model such as an SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set working directory\n",
    "import os\n",
    "import sys\n",
    "project_root = '/Users/kgedney/Documents/georgetown/anly580/anly580-wine-project'\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle load data \n",
    "# ref: https://www.kaggle.com/zynicide/wine-reviews#winemag-data_first150k.csv\n",
    "df_full = pd.read_csv('data/winemag-data_first150k.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'country', 'description', 'designation', 'points',\n",
       "       'price', 'province', 'region_1', 'region_2', 'variety', 'winery'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select wines with over 1050 tasting notes (to make an even 30 varities)\n",
    "variety_counts = pd.DataFrame(df_full['variety'].value_counts())\n",
    "varieties      = list(variety_counts.index[variety_counts['variety'] > 1050])\n",
    "len(varieties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full[df_full['variety'].isin(varieties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chardonnay                       14482\n",
       "Pinot Noir                       14291\n",
       "Cabernet Sauvignon               12800\n",
       "Red Blend                        10062\n",
       "Bordeaux-style Red Blend          7347\n",
       "Sauvignon Blanc                   6320\n",
       "Syrah                             5825\n",
       "Riesling                          5524\n",
       "Merlot                            5070\n",
       "Zinfandel                         3799\n",
       "Sangiovese                        3345\n",
       "Malbec                            3208\n",
       "White Blend                       2824\n",
       "Rosé                              2817\n",
       "Tempranillo                       2556\n",
       "Nebbiolo                          2241\n",
       "Portuguese Red                    2216\n",
       "Sparkling Blend                   2004\n",
       "Shiraz                            1970\n",
       "Corvina, Rondinella, Molinara     1682\n",
       "Rhône-style Red Blend             1505\n",
       "Barbera                           1365\n",
       "Pinot Gris                        1365\n",
       "Cabernet Franc                    1363\n",
       "Sangiovese Grosso                 1346\n",
       "Pinot Grigio                      1305\n",
       "Viognier                          1263\n",
       "Bordeaux-style White Blend        1261\n",
       "Champagne Blend                   1238\n",
       "Port                              1058\n",
       "Name: variety, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.variety.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kgedney/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# map classes to integers\n",
    "df['variety_code'] = pd.Categorical(df.variety).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set classes\n",
    "x = df.description.values\n",
    "y = df.variety_code.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and train\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=522)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline: Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11562917662306103"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# majority class prediction\n",
    "np.mean(y_test == 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kgedney/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(98761, 26413)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocess\n",
    "tfidf_vec   = TfidfVectorizer()\n",
    "x_train_vec = tfidf_vec.fit_transform(x_train)\n",
    "x_test_vec  = tfidf_vec.transform(x_test)\n",
    "x_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8066906970151068\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "from sklearn.svm import LinearSVC\n",
    "clf             = LinearSVC().fit(x_train_vec, y_train)\n",
    "predicted       = clf.predict(x_test_vec)\n",
    "predicted_score = clf.decision_function(x_test_vec)\n",
    "print('accuracy', metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7500708760277024\n",
      "0.7957150378680491\n",
      "0.8066906970151068\n",
      "0.8143048074197076\n",
      "0.8170183467660281\n",
      "0.8142238062451905\n"
     ]
    }
   ],
   "source": [
    "# grid search on C\n",
    "\n",
    "def fit_svc(C=1):\n",
    "    clf             = LinearSVC(C=C).fit(x_train_vec, y_train)\n",
    "    predicted       = clf.predict(x_test_vec)\n",
    "    predicted_score = clf.decision_function(x_test_vec)\n",
    "    return metrics.accuracy_score(y_test, predicted)\n",
    "\n",
    "for C in [0.1, 0.5, 1, 2, 4, 8]:\n",
    "    print(fit_svc(C=C))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Data for Keras Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kgedney/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, CuDNNLSTM, LSTM, Embedding, Bidirectional, GlobalAveragePooling1D, Conv1D, Activation, Flatten, Dropout, MaxPooling1D, Embedding, GlobalMaxPooling1D\n",
    "\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n"
     ]
    }
   ],
   "source": [
    "# data preprocess\n",
    "x = df.description.values\n",
    "y = df.variety_code.values\n",
    "\n",
    "# create sequences\n",
    "max_features = 25000\n",
    "tokenizer    = Tokenizer(num_words = max_features)\n",
    "tokenizer.fit_on_texts(x)\n",
    "x_sequences  = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "# pad each sequence to be max length\n",
    "maxlen = max(len(x) for x in x_sequences)\n",
    "print(maxlen)\n",
    "x_sequences = sequence.pad_sequences(x_sequences, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split test and train\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_sequences, y, test_size=0.20, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(input_dim=max_features,\n",
    "                    output_dim=128))\n",
    "\n",
    "# we add a GlobalAveragePooling1D, which will average the embeddings\n",
    "# of all words in the document\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "model1.add(Dense(100, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.01) # speed up optimization\n",
    "model1.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 98761 samples, validate on 24691 samples\n",
      "Epoch 1/16\n",
      "98761/98761 [==============================] - 18s 178us/step - loss: 2.2507 - acc: 0.3763 - val_loss: 1.3796 - val_acc: 0.6031\n",
      "Epoch 2/16\n",
      "98761/98761 [==============================] - 18s 181us/step - loss: 1.1765 - acc: 0.6598 - val_loss: 0.9768 - val_acc: 0.7089\n",
      "Epoch 3/16\n",
      "98761/98761 [==============================] - 18s 180us/step - loss: 0.8913 - acc: 0.7403 - val_loss: 0.8513 - val_acc: 0.7431\n",
      "Epoch 4/16\n",
      "98761/98761 [==============================] - 16s 161us/step - loss: 0.7511 - acc: 0.7794 - val_loss: 0.7874 - val_acc: 0.7630\n",
      "Epoch 5/16\n",
      "98761/98761 [==============================] - 17s 172us/step - loss: 0.6585 - acc: 0.8057 - val_loss: 0.7539 - val_acc: 0.7759\n",
      "Epoch 6/16\n",
      "98761/98761 [==============================] - 16s 163us/step - loss: 0.5836 - acc: 0.8268 - val_loss: 0.7252 - val_acc: 0.7874\n",
      "Epoch 7/16\n",
      "98761/98761 [==============================] - 17s 174us/step - loss: 0.5289 - acc: 0.8433 - val_loss: 0.7097 - val_acc: 0.7936\n",
      "Epoch 8/16\n",
      "98761/98761 [==============================] - 17s 177us/step - loss: 0.4760 - acc: 0.8592 - val_loss: 0.6988 - val_acc: 0.7986\n",
      "Epoch 9/16\n",
      "98761/98761 [==============================] - 19s 190us/step - loss: 0.4402 - acc: 0.8693 - val_loss: 0.6875 - val_acc: 0.8045\n",
      "Epoch 10/16\n",
      "98761/98761 [==============================] - 16s 165us/step - loss: 0.4079 - acc: 0.8793 - val_loss: 0.6926 - val_acc: 0.8076\n",
      "Epoch 11/16\n",
      "98761/98761 [==============================] - 16s 167us/step - loss: 0.3791 - acc: 0.8860 - val_loss: 0.6921 - val_acc: 0.8126\n",
      "Epoch 12/16\n",
      "98761/98761 [==============================] - 18s 183us/step - loss: 0.3559 - acc: 0.8934 - val_loss: 0.6974 - val_acc: 0.8126\n",
      "Epoch 13/16\n",
      "98761/98761 [==============================] - 18s 180us/step - loss: 0.3361 - acc: 0.8989 - val_loss: 0.7080 - val_acc: 0.8143\n",
      "Epoch 14/16\n",
      "98761/98761 [==============================] - 16s 166us/step - loss: 0.3148 - acc: 0.9048 - val_loss: 0.7159 - val_acc: 0.8174\n",
      "Epoch 15/16\n",
      "98761/98761 [==============================] - 16s 164us/step - loss: 0.3008 - acc: 0.9089 - val_loss: 0.7294 - val_acc: 0.8194\n",
      "Epoch 16/16\n",
      "98761/98761 [==============================] - 21s 209us/step - loss: 0.2860 - acc: 0.9120 - val_loss: 0.7388 - val_acc: 0.8192\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x_train, y_train,\n",
    "            batch_size=256,\n",
    "            epochs=16,\n",
    "            validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24691/24691 [==============================] - 1s 31us/step\n",
      "accuracy 0.8191648778834874\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', model1.evaluate(x_test, y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98761/98761 [==============================] - 2s 23us/step\n",
      "train accuracy 0.9514383207952491\n"
     ]
    }
   ],
   "source": [
    "print('train accuracy', model1.evaluate(x_train, y_train)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
